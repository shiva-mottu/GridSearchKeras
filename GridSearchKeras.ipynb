{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XB7vspORmpSW"
   },
   "source": [
    "## How to tune some hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T12:14:58.618895Z",
     "start_time": "2019-10-17T12:14:58.605179Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1570727101049,
     "user": {
      "displayName": "Michel RIVEILL",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBpjXdcyobvxepBqu30kSPOc0oQdMx-MHBvaldSBg=s64",
      "userId": "03069148770389064022"
     },
     "user_tz": -120
    },
    "id": "LkBh3ssbmY2G",
    "outputId": "83a17336-2f3a-485c-d798-b3c9aa7e3050"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T12:15:03.036500Z",
     "start_time": "2019-10-17T12:15:00.331403Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2261,
     "status": "ok",
     "timestamp": 1570727453166,
     "user": {
      "displayName": "Michel RIVEILL",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBpjXdcyobvxepBqu30kSPOc0oQdMx-MHBvaldSBg=s64",
      "userId": "03069148770389064022"
     },
     "user_tz": -120
    },
    "id": "urF_tW5MpL58",
    "outputId": "17367cad-2faa-4f67-b525-aa955aab6cbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000, 10), (28, 28))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# load dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "input_shape = (X_train.shape[1],X_train.shape[2], )\n",
    "\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "X_train.shape, y_train.shape, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T12:15:06.160533Z",
     "start_time": "2019-10-17T12:15:05.307286Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2497,
     "status": "ok",
     "timestamp": 1570727526841,
     "user": {
      "displayName": "Michel RIVEILL",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBpjXdcyobvxepBqu30kSPOc0oQdMx-MHBvaldSBg=s64",
      "userId": "03069148770389064022"
     },
     "user_tz": -120
    },
    "id": "iouB8uZ5pJop",
    "outputId": "ded1a3f7-2a8e-45d2-a6a5-c27f408ce21f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 23,860\n",
      "Trainable params: 23,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(neurons=30, dropout_rate=0.5,\n",
    "                 init_mode='uniform', weight_constraint=0,\n",
    "                 optimizer='adam', learn_rate=0.01, momentum=0,\n",
    "                 activation='relu'):\n",
    "    \n",
    "    # create model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Flatten()(inputs)\n",
    "    x = Dense(neurons,\n",
    "              kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint),\n",
    "              activation=activation)(x)\n",
    "    \n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                   kernel_initializer=init_mode,\n",
    "                   activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    # Compile model\n",
    "    #optimizer = optimizer(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = create_model()\n",
    "\n",
    "# Print the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T12:22:38.005458Z",
     "start_time": "2019-10-17T12:22:37.995148Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "y8DCQzDbpMDp"
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "#batch_size = [8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "batch_size = [8, 1024]\n",
    "#epochs = [10, 50, 100]\n",
    "epochs = [10]\n",
    "#optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "optimizer = ['SGD']\n",
    "#learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "learn_rate = [0.001, 0.3]\n",
    "#momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "#init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "#activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "activation = ['relu', 'sigmoid']\n",
    "\n",
    "#weight_constraint = [1, 2, 3, 4, 5]\n",
    "#dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "dropout_rate = [0.0, 0.9]\n",
    "#neurons = [8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "neurons = [8, 1024]\n",
    "\n",
    "#param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer=optimizer, learn_rate=learn_rate, momentum=momentum, init_mode=init_mode)\n",
    "param_grid = dict(batch_size=batch_size\n",
    "                  ,neurons=neurons\n",
    "                  ,dropout_rate=dropout_rate\n",
    "                  ,epochs=epochs\n",
    "                  ,optimizer=optimizer \n",
    "                  ,learn_rate=learn_rate \n",
    "                  #,momentum=momentum\n",
    "                  ,activation=activation\n",
    "                  #,init_mode=init_mode\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T12:25:35.586028Z",
     "start_time": "2019-10-17T12:22:40.994719Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 98633,
     "status": "ok",
     "timestamp": 1570727348156,
     "user": {
      "displayName": "Michel RIVEILL",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBpjXdcyobvxepBqu30kSPOc0oQdMx-MHBvaldSBg=s64",
      "userId": "03069148770389064022"
     },
     "user_tz": -120
    },
    "id": "HC2HP5dxpMLS",
    "outputId": "9b830599-3778-40d7-e78e-5045e4aa4178"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krant\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\krant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\krant\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.3251 - accuracy: 0.9000\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.3251 - accuracy: 0.9000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.3251 - accuracy: 0.9000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.3250 - accuracy: 0.9000\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.3250 - accuracy: 0.9000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.3250 - accuracy: 0.9000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.3250 - accuracy: 0.9000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.3250 - accuracy: 0.9000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.3250 - accuracy: 0.9000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.3250 - accuracy: 0.9000\n",
      "Best: 0.900000 using {'activation': 'relu', 'batch_size': 8, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 8, 'optimizer': 'SGD'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=2)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "# We use only a small part of the dataset\n",
    "grid_result = grid.fit(X_train[:1000], y_train[:1000], verbose=2)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T12:32:56.967935Z",
     "start_time": "2019-10-17T12:32:56.956654Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VSLg0yNnpaJD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\t\tparams\n",
      "--------------------------------\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 8, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 8, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 8, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 8, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 8, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 8, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 8, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 8, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 1024, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 1024, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 1024, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'relu', 'batch_size': 1024, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 8, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 8, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 8, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 8, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 8, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 8, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 8, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 8, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 1024, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 1024, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.001, 'neurons': 1024, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 1024, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 8, 'optimizer': 'SGD'}\n",
      "0.900000 with: {'activation': 'sigmoid', 'batch_size': 1024, 'dropout_rate': 0.9, 'epochs': 10, 'learn_rate': 0.3, 'neurons': 1024, 'optimizer': 'SGD'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "#stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "print(\"mean\\t\\tparams\")\n",
    "print(\"--------------------------------\")\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"%f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iwl71_Ngogc2"
   },
   "source": [
    "## Tips for Hyperparameter Optimization\n",
    "\n",
    "This section lists some handy tips to consider when tuning hyperparameters of your neural network.\n",
    "\n",
    "* **k-fold Cross Validation.** You can see that the results from the examples in this post show some variance. A default cross-validation of 3 was used, but perhaps k=5 or k=10 would be more stable. Carefully choose your cross validation configuration to ensure your results are stable.\n",
    "* **Review the Whole Grid.** Do not just focus on the best result, review the whole grid of results and look for trends to support configuration decisions.\n",
    "* **Parallelize.** Use all your cores if you can, neural networks are slow to train and we often want to try a lot of different parameters. Consider spinning up a lot of AWS instances.\n",
    "* **Use a Sample of Your Dataset.** Because networks are slow to train, try training them on a smaller sample of your training dataset, just to get an idea of general directions of parameters rather than optimal configurations.\n",
    "* **Start with Coarse Grids.** Start with coarse-grained grids and zoom into finer grained grids once you can narrow the scope.\n",
    "* **Do not Transfer Results.** Results are generally problem specific. * Try to avoid favorite configurations on each new problem that you see. It is unlikely that optimal results you discover on one problem will transfer to your next project. Instead look for broader trends like number of layers or relationships between parameters.\n",
    "* **Reproducibility is a Problem.** Although we set the seed for the random number generator in NumPy, the results are not 100% reproducible. There is more to reproducibility when grid searching wrapped Keras models than is presented in this post.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GridSearchKeras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
